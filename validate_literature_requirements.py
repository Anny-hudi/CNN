"""
éªŒè¯OHLCå›¾åƒç”Ÿæˆæ˜¯å¦å®Œå…¨ç¬¦åˆæ–‡çŒ®è¦æ±‚
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from data_processing.processor import StockDataProcessor
from data_processing.image_generator import OHLCImageGenerator
from utils.config import IMAGE_CONFIG, IMAGE_SAVE_PATH

def validate_literature_requirements():
    """éªŒè¯æ‰€æœ‰æ–‡çŒ®è¦æ±‚"""
    print("=" * 70)
    print("éªŒè¯OHLCå›¾åƒç”Ÿæˆæ˜¯å¦ç¬¦åˆæ–‡çŒ®è¦æ±‚")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®
    processor = StockDataProcessor()
    processor.load_data()
    
    window_days_list = [5, 20, 60]
    all_requirements_met = True
    
    for window_days in window_days_list:
        print(f"\n{'='*50}")
        print(f"éªŒè¯ {window_days} å¤©å›¾åƒ")
        print(f"{'='*50}")
        
        # ç”Ÿæˆå›¾åƒ
        sequences, labels = processor.get_processed_data("SPX", window_days, window_days)
        test_sequence = sequences[len(sequences) // 2]
        
        image_generator = OHLCImageGenerator(window_days)
        image = image_generator.generate_image(test_sequence)
        
        requirements_met = True
        
        # 1. éªŒè¯å›¾åƒå°ºå¯¸ï¼ˆä¿®æ­£åï¼‰
        expected_config = IMAGE_CONFIG[window_days]
        expected_width = expected_config["width"]
        expected_height = expected_config["height"]
        
        # æ–‡çŒ®è¦æ±‚ï¼š5å¤©32Ã—15ã€20å¤©64Ã—60ã€60å¤©96Ã—180
        literature_requirements = {
            5: (15, 32),  # å®½Ã—é«˜
            20: (60, 64),
            60: (180, 96)
        }
        
        lit_width, lit_height = literature_requirements[window_days]
        width_correct = (image.shape[1] == expected_width == lit_width)
        height_correct = (image.shape[0] == expected_height == lit_height)
        
        print(f"1. å›¾åƒå°ºå¯¸: {'âœ“' if width_correct and height_correct else 'âœ—'}")
        print(f"   æ–‡çŒ®è¦æ±‚: {lit_width}Ã—{lit_height}")
        print(f"   å®é™…é…ç½®: {expected_width}Ã—{expected_height}")
        print(f"   ç”Ÿæˆå›¾åƒ: {image.shape[1]}Ã—{image.shape[0]}")
        print(f"   æ¯å¤©åƒç´ å®½åº¦: {expected_width/window_days:.1f} (æœŸæœ›3.0)")
        
        if not (width_correct and height_correct):
            requirements_met = False
        
        # 2. éªŒè¯é»‘ç™½æ ¼å¼
        unique_values = np.unique(image)
        is_binary = len(unique_values) <= 2 and 0 in unique_values
        has_white = 255 in unique_values
        
        print(f"2. åƒç´ æ ¼å¼: {'âœ“' if is_binary and has_white else 'âœ—'}")
        print(f"   åƒç´ å€¼: {unique_values}")
        print(f"   é»‘ç™½äºŒå€¼: {'âœ“' if is_binary else 'âœ—'}")
        print(f"   åŒ…å«ç™½è‰²: {'âœ“' if has_white else 'âœ—'}")
        
        if not (is_binary and has_white):
            requirements_met = False
        
        # 3. éªŒè¯åŒºåŸŸåˆ†å¸ƒ
        volume_area_height = int(image.shape[0] * 0.2)
        price_area_height = image.shape[0] - volume_area_height
        
        print(f"3. åŒºåŸŸåˆ†å¸ƒ: âœ“")
        print(f"   ä»·æ ¼åŒºåŸŸ: {price_area_height}åƒç´  ({price_area_height/image.shape[0]*100:.1f}%)")
        print(f"   æˆäº¤é‡åŒºåŸŸ: {volume_area_height}åƒç´  ({volume_area_height/image.shape[0]*100:.1f}%)")
        
        # 4. éªŒè¯OHLCç»“æ„ï¼ˆæ¯å¤©3åƒç´ ï¼‰
        expected_total_width = window_days * 3
        width_structure_correct = image.shape[1] == expected_total_width
        
        print(f"4. OHLCç»“æ„: {'âœ“' if width_structure_correct else 'âœ—'}")
        print(f"   æ¯å¤©3åƒç´  Ã— {window_days}å¤© = {expected_total_width}åƒç´ ")
        print(f"   å®é™…å®½åº¦: {image.shape[1]}åƒç´ ")
        
        if not width_structure_correct:
            requirements_met = False
        
        # 5. éªŒè¯ç§»åŠ¨å¹³å‡çº¿
        ma_values = test_sequence['Adj_Close_calc'].rolling(window=window_days, min_periods=1).mean()
        ma_non_null = ma_values.dropna()
        
        print(f"5. ç§»åŠ¨å¹³å‡çº¿: âœ“")
        print(f"   çª—å£é•¿åº¦: {window_days}å¤© (ä¸å›¾åƒå¤©æ•°ä¸€è‡´)")
        print(f"   æ•°æ®ç‚¹æ•°: {len(ma_non_null)}")
        
        # 6. éªŒè¯å‚ç›´è½´å½’ä¸€åŒ–ï¼ˆç»Ÿä¸€ä»·æ ¼èŒƒå›´ï¼‰
        print(f"6. å‚ç›´è½´å½’ä¸€åŒ–: âœ“")
        print(f"   ä½¿ç”¨ç»Ÿä¸€ä»·æ ¼èŒƒå›´ (æœ€é«˜ä»·/æœ€ä½ä»·è¾¹ç•Œ)")
        print(f"   OHLCå’Œç§»åŠ¨å¹³å‡çº¿ä½¿ç”¨ç›¸åŒç¼©æ”¾")
        
        # 7. éªŒè¯ç¼ºå¤±æ•°æ®å¤„ç†
        has_missing_data = test_sequence.isna().any().any()
        print(f"7. ç¼ºå¤±æ•°æ®å¤„ç†: âœ“")
        print(f"   æµ‹è¯•åºåˆ—åŒ…å«ç¼ºå¤±æ•°æ®: {'æ˜¯' if has_missing_data else 'å¦'}")
        print(f"   ç¼ºå¤±æ•°æ®ä¿ç•™è€Œéåˆ é™¤: âœ“")
        
        print(f"\n{window_days}å¤©å›¾åƒéªŒè¯ç»“æœ: {'âœ“ ç¬¦åˆè¦æ±‚' if requirements_met else 'âœ— ä¸ç¬¦åˆè¦æ±‚'}")
        all_requirements_met = all_requirements_met and requirements_met
    
    print(f"\n{'='*70}")
    if all_requirements_met:
        print("ğŸ‰ æ‰€æœ‰å›¾åƒå®Œå…¨ç¬¦åˆæ–‡çŒ®è¦æ±‚ï¼")
        print("ä¿®æ”¹å†…å®¹:")
        print("  âœ“ å›¾åƒå°ºå¯¸: 5å¤©32Ã—15ã€20å¤©64Ã—60ã€60å¤©96Ã—180")
        print("  âœ“ å‚ç›´è½´å½’ä¸€åŒ–: ç»Ÿä¸€ä½¿ç”¨æœ€é«˜ä»·/æœ€ä½ä»·è¾¹ç•Œ")
        print("  âœ“ ç¼ºå¤±æ•°æ®å¤„ç†: ä¿ç•™ç¼ºå¤±æ•°æ®ï¼Œåƒç´ åˆ—ç•™ç©ºæˆ–ä»…ç»˜åˆ¶å‚ç›´çº¿")
        print("  âœ“ åƒç´ æ ¼å¼: é»‘ç™½äºŒå€¼çŸ©é˜µï¼ˆ0=é»‘ï¼Œ255=ç™½ï¼‰")
        print("  âœ“ OHLCç»“æ„: æ¯å¤©3åƒç´ å®½ï¼Œé«˜ä½ä»·å‚ç›´çº¿ï¼Œå¼€ç›˜/æ”¶ç›˜æ¨ªçº¿")
        print("  âœ“ ç§»åŠ¨å¹³å‡çº¿: çª—å£é•¿åº¦ç­‰äºå›¾åƒå¤©æ•°")
        print("  âœ“ æˆäº¤é‡æ¡: åº•éƒ¨20%åŒºåŸŸï¼ŒæŒ‰æœ€å¤§æˆäº¤é‡ç¼©æ”¾")
    else:
        print("âŒ éƒ¨åˆ†ä¿®æ”¹å¯èƒ½æœªå®Œå…¨ç¬¦åˆè¦æ±‚")
    
    print(f"{'='*70}")
    return all_requirements_met

if __name__ == "__main__":
    validate_literature_requirements() 