"""
æ›´æ–°åçš„CNNè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿä¸»ç¨‹åº
ä¸¥æ ¼æŒ‰ç…§Jiang, Kelly & Xiu (2023)è®ºæ–‡è¦æ±‚å®ç°
"""
import os
import numpy as np
import matplotlib.pyplot as plt
from data_processing.processor import StockDataProcessor
from data_processing.image_generator import OHLCImageGenerator
from models.cnn_model import StockCNN
from models.trainer import ModelTrainer
from utils.evaluation import ModelEvaluator
from utils.benchmarks import BenchmarkSignals
from utils.config import IMAGE_CONFIG, TRAIN_CONFIG, EVAL_CONFIG, IMAGE_SAVE_PATH

def run_paper_experiment(symbol="SPX", window_days=20, test_mode=True):
    """
    è¿è¡Œè®ºæ–‡å®éªŒï¼ˆä¸¥æ ¼æŒ‰ç…§è®ºæ–‡è¦æ±‚ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        window_days: æ—¶é—´çª—å£å¤©æ•°ï¼ˆ5/20/60ï¼‰
        test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
    """
    print(f"\n{'='*60}")
    print(f"Jiang, Kelly & Xiu (2023) è®ºæ–‡å¤ç°å®éªŒ")
    print(f"æ¨¡å‹: I{window_days}/R{window_days} ({'å‘¨' if window_days==5 else 'æœˆ' if window_days==20 else 'å­£'}ç­–ç•¥)")
    print(f"{'='*60}")
    
    if test_mode:
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨10%æ•°æ®é‡")
    
    # 1. æ•°æ®åŠ è½½ä¸å¤„ç†ï¼ˆè®ºæ–‡è¦æ±‚ï¼šCRSPä¸ªè‚¡æ•°æ®ï¼Œ1993-2019ï¼‰
    print("\n1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†...")
    data_fraction = 0.1 if test_mode else 1.0
    processor = StockDataProcessor(data_fraction=data_fraction)
    processor.load_data()
    
    # è·å–åºåˆ—æ•°æ®ï¼ˆç›‘ç£æœŸ=æŒæœ‰æœŸï¼‰
    sequences, labels, dates = processor.get_processed_data(symbol, window_days, window_days)
    print(f"   å…±ç”Ÿæˆ {len(sequences)} ä¸ªæ ·æœ¬")
    print(f"   ç›‘ç£æœŸ=æŒæœ‰æœŸ: {window_days}å¤©")
    
    # 2. ç”ŸæˆOHLCå›¾åƒï¼ˆè®ºæ–‡è¦æ±‚ï¼šä¸¥æ ¼é»‘ç™½ï¼Œæ¯å¤©3åƒç´ ï¼‰
    print("\n2. ç”ŸæˆOHLCå›¾åƒ...")
    image_generator = OHLCImageGenerator(window_days)
    
    # æŒ‰è®ºæ–‡è¦æ±‚ï¼šè®­ç»ƒæœŸ1993-2000ï¼Œæµ‹è¯•æœŸ2001-2019
    import pandas as pd
    years = pd.to_datetime(dates).year
    train_mask = (years >= 1993) & (years <= 2000)
    test_mask = years >= 2001
    
    print(f"   æ•°æ®å¹´ä»½èŒƒå›´: {years.min()}-{years.max()}")
    print(f"   è®­ç»ƒæœŸæ ·æœ¬: {np.sum(train_mask)}")
    print(f"   æµ‹è¯•æœŸæ ·æœ¬: {np.sum(test_mask)}")
    
    # åŸºäºè®­ç»ƒé›†æ‹Ÿåˆå½’ä¸€åŒ–ç»Ÿè®¡é‡
    train_sequences = [seq for seq, is_train in zip(sequences, train_mask) if is_train]
    if len(train_sequences) > 0:
        print("   æ­£åœ¨è®¡ç®—è®­ç»ƒé›†å½’ä¸€åŒ–ç»Ÿè®¡é‡...")
        image_generator.fit_normalizer(train_sequences)
    
    images = image_generator.generate_batch(sequences)
    print(f"   å›¾åƒå°ºå¯¸: {images.shape}")
    
    # 3. æ„å»ºCNNæ¨¡å‹ï¼ˆè®ºæ–‡è¦æ±‚ï¼šI5(2å—)ã€I20(3å—)ã€I60(4å—)ï¼‰
    print("\n3. æ„å»ºCNNæ¨¡å‹...")
    cnn = StockCNN(window_days)
    model = cnn.build_model(input_shape=images.shape[1:])
    cnn.compile_model(learning_rate=TRAIN_CONFIG["learning_rate"])
    
    print("   æ¨¡å‹ç»“æ„:")
    cnn.summary()
    
    # 4. è®­ç»ƒæ¨¡å‹ï¼ˆè®ºæ–‡è¦æ±‚ï¼š5æ¬¡ç‹¬ç«‹è®­ç»ƒå–å¹³å‡ï¼‰
    print("\n4. è®­ç»ƒæ¨¡å‹...")
    trainer = ModelTrainer(model, window_days)
    X_train, X_val, X_test, y_train, y_val, y_test = trainer.prepare_data(images, labels, dates)
    
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬") 
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    # è®ºæ–‡è¦æ±‚ï¼šæ¯ä¸ªæ¨¡å‹é…ç½®ç‹¬ç«‹è®­ç»ƒ5æ¬¡å–å¹³å‡
    if not test_mode:
        print(f"   å¼€å§‹{TRAIN_CONFIG['n_ensemble']}æ¬¡ç‹¬ç«‹è®­ç»ƒ...")
        models, histories = trainer.train_multiple_runs(
            X_train, X_val, y_train, y_val, 
            n_runs=TRAIN_CONFIG["n_ensemble"]
        )
        
        # é›†æˆé¢„æµ‹
        ensemble_pred = trainer.predict_ensemble(models, X_test)
    else:
        # æµ‹è¯•æ¨¡å¼ï¼šå•æ¬¡è®­ç»ƒ
        print("   æµ‹è¯•æ¨¡å¼ï¼šå•æ¬¡è®­ç»ƒ")
        history = trainer.train(X_train, X_val, y_train, y_val)
        ensemble_pred = model.predict(X_test, verbose=0)
    
    # 5. æ¨¡å‹è¯„ä¼°ï¼ˆè®ºæ–‡è¦æ±‚ï¼šç­‰æƒ/ä»·å€¼åŠ æƒã€H-Lç­–ç•¥ã€å¤æ™®æ¯”ç‡ï¼‰
    print("\n5. è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    evaluator = ModelEvaluator()
    
    # è®¡ç®—æµ‹è¯•é›†æ”¶ç›Šç‡
    test_returns = []
    for i in range(len(y_test)):
        seq_idx = len(sequences) - len(y_test) + i
        if seq_idx + 1 < len(sequences):
            current_price = sequences[seq_idx].iloc[-1]['Adj_Close_calc']
            future_price = sequences[seq_idx + 1].iloc[-1]['Adj_Close_calc']
            test_returns.append((future_price - current_price) / current_price)
        else:
            test_returns.append(0.0)
    
    # è¯„ä¼°é¢„æµ‹ç»“æœ
    results = evaluator.evaluate_predictions(
        predictions=ensemble_pred,
        actual_returns=test_returns,
        holding_period_days=window_days
    )
    
    # æ‰“å°è¯„ä¼°æŠ¥å‘Š
    evaluator.print_evaluation_report(results, window_days)
    
    # 6. åŸºå‡†ä¿¡å·å¯¹æ¯”ï¼ˆè®ºæ–‡è¦æ±‚ï¼šMOMã€STRã€WSTRã€TRENDï¼‰
    print("\n6. åŸºå‡†ä¿¡å·å¯¹æ¯”...")
    benchmark_calculator = BenchmarkSignals()
    
    # å‡†å¤‡åŸºå‡†ä¿¡å·æ•°æ®
    stock_data = {symbol: {
        'prices': [seq['Adj_Close_calc'].iloc[-1] for seq in sequences],
        'returns': [seq['Return'].iloc[-1] if not pd.isna(seq['Return'].iloc[-1]) else 0.0 for seq in sequences]
    }}
    
    print("   åŸºå‡†ä¿¡å·è¡¨ç°:")
    for benchmark_type in EVAL_CONFIG["benchmark_signals"]:
        deciles, signals = benchmark_calculator.create_benchmark_portfolios(
            stock_data, benchmark_type
        )
        
        if deciles is not None:
            benchmark_perf = benchmark_calculator.evaluate_benchmark_performance(
                deciles, stock_data, window_days
            )
            
            if benchmark_perf:
                print(f"   {benchmark_type}: H-Læ”¶ç›Š={benchmark_perf['long_short_return']:.4f}, "
                      f"å¤æ™®æ¯”ç‡={benchmark_perf['sharpe_ratio']:.4f}")
        else:
            print(f"   {benchmark_type}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("CNNè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - è®ºæ–‡å¤ç°ç‰ˆ")
    print("Jiang, Kelly & Xiu (2023): (Re-)Imag(in)ing Price Trends")
    print("="*60)
    
    # è®ºæ–‡è¦æ±‚çš„ä¸‰ä¸ªæ¨¡å‹ï¼šI5/R5, I20/R20, I60/R60
    window_days_list = [5, 20, 60]
    all_results = {}
    
    for window_days in window_days_list:
        try:
            print(f"\nå¼€å§‹ {window_days} å¤©æ¨¡å‹å®éªŒ...")
            results = run_paper_experiment("SPX", window_days, test_mode=True)
            all_results[window_days] = results
            
            print(f"\nâœ“ I{window_days}/R{window_days} æ¨¡å‹æµ‹è¯•å®Œæˆ")
                
        except Exception as e:
            print(f"\nâœ— I{window_days}/R{window_days} æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
    
    # æ‰“å°æ‰€æœ‰æ¨¡å‹çš„æ¯”è¾ƒç»“æœ
    print(f"\n{'='*60}")
    print("è®ºæ–‡å¤ç°ç»“æœæ€»ç»“")
    print(f"{'='*60}")
    print(f"{'æ¨¡å‹':^10}{'å‡†ç¡®ç‡':^12}{'ç­‰æƒH-Læ”¶ç›Š':^15}{'ç­‰æƒå¤æ™®æ¯”ç‡':^15}")
    print("-"*60)
    
    for days, res in all_results.items():
        if res:
            eq_results = res['equal_weight']
            print(f"I{days}/R{days}:^10{eq_results['long_short_return']:^15.4f}{eq_results['long_short_sharpe']:^15.4f}")
    
    print(f"\n{'='*60}")
    print("è®ºæ–‡å¤ç°å®Œæˆï¼")
    print("æ³¨æ„ï¼šå½“å‰ä½¿ç”¨æŒ‡æ•°æ•°æ®ï¼Œå®Œæ•´å¤ç°éœ€è¦CRSPä¸ªè‚¡æ•°æ®")
    print("å¦‚éœ€å®Œæ•´è®­ç»ƒï¼Œè¯·ä¿®æ”¹ test_mode=False")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
